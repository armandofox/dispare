\chapter{Test Cases}
\label{example}
This section presents an explanation of the test cases that were
designed for \dispare project.  
The first test case will be used to examine the basic functionality
of \dispare as far as time step sequencing and  basic event state 
variables 
management. The second simulation test is used to examine
the synchronous control features of \dispare.  The next sections contain
more detailed information about each of the simulation test cases. There is
an additional section that gives some basic guidelines for constructing 
simulations.
 
\section{Simple Event Simulation}
This test case is used to  examine \dispare's ability to
deal with basic events, in which one event produces something and it is
consumed by some other event.  The simulation demonstrates a simple producer
and multiple consumers event chain.  The following diagram
demonstrates how the simulation test is setup:
 
\begin{figure}
\label{simtestA}
\centerline{\psfig{figure=simtesta.ps}}
\caption{ Simulation Test Case A, Basic Functionality Evaluation}
\end{figure}

 
This simulation sets up a producer-consumer relationship, where the
{\bf Producer} generates an object and the {\bf Consumers} will
absorb/receive the object and store it in an internal queue, which will
be flushed once the queue is full.  The next section describes
in detail the roles of each to the events.
 
\subsection{Producer}
The {\bf Producer} event is responsible for generating an object in a
variable amount of time.  There will be a total of 100 objects
that will be generated by this event.  The even number objects will 
be sent to {\em Consumer:1} and the odd number will be sent to 
{\em Consumer:2}.
The time at which each of these object is randomly chosen between 1 and
50 by using {\tt rand()}.
Once an object is generated and sent, the {\bf Producer}
will call itself with a time increase equal to random value
generated.  The Producer will stop generating objects once 100
objects have been generated.  The following output will also be
recorded into a file to be used for evaluation of the simulator:
\begin{itemize}
\item Object Identification Number
\item Time at which object will be received by {\em Consumer}
\item Time at which the next object is generated
\end{itemize}
The following is example output that should be produced from \dispare
for the output file for the {\bf Producer Event}:
\begin{verbatim}

Time[Object_Id] = Time at which object should arrive at next event
Next Time = Time at which the next object is planned to be generated

Time[1] = 1:  Next Time = 64
Time[2] = 64: Next Time = 66
Time[3] = 66: Next Time = 78
\end{verbatim}


\subsection{Consumer}
The consumer event will be responsible for taking the object and placing
the object in an internal queue of finite size.  Once the queue is full
the consumer will flush the queue into a file marking the flush time,
Object ID that caused the flush, and object reception time by the
consumer. A busy work loop is included, which represents some work that
the consumer would do that takes almost no time with respect to the
simulation.  In a sequential processing environment this busy work loop
respesents a large amount of real processing time that would be lost
from other events, but inn \dispare this loop will not affect other
processing events because the events are being processed in parallel
(assuming multiple processors are being used).
 
\subsection{Simulation Test Objectives}
This simulation test is designed to examine some of the important
and delicate features of \dispare.
The {\bf Producer} self-loop is designed to test whether or not
\dispare is properly updating the time for all events.  The {\bf Producer}
is used to deterime that other spawned events are occuring correctly in
simulated time.  The output files from the {\bf Producer Event} can be
compared to both Consumers' output files to check the validity of
information being passed from event to event.  The Consumer events are
used to validate the state variables of the events. The Consumer event
manages a FIFO queue, meaning that in the output files all the object
ID's should be in ascending order as well as the time stamps.  The
Consumer is also tests \dispare's ability to buffer event messages while
the receiving event is still active.  These features demonstrate how
\dispare can speed up the simulation, The most time consuming part of
any simulation is the amount of work in an event that needs to do be
processed before another event can take place.  Since \dispare uses
parallel processing for running the events, events can be run in
parallel allowing more overall work to be done in the simulation.  The
speedup of simulation is therefore based upon the number of independent
events and the number of processors.

 
\subsection{Results}
The results of the test were very positive.  All transactions executed
correctly at the expected simulation times and the all event varibles
were being properly maintained.  The contents of the report files {\tt
producer.rep}, {\tt consume1.rep} and {\tt consume2.rep} generated by
the test case are attached to the end of this report.
File {\tt produce.rep} shows the producer
sequence of events being sent to either {\bf Consumer-1} or {\bf
Consumer-2}.  This output also shows the correctness of the time
updating during the self loop of {\bf Producer}.  The Consumers' Event
reports indicate the Object Id. and Time at which the object was
received.

\subsection {Performance Evaluation}
The following chart shows the execution times of the simulation in terms of
real user time, or what one might call Wall Clock time.  It should
be noted that some the delays in the system may be introduced by
the fact that simulation is performing a large amount of disk-i/o
for writing out the event report. All runs were performed on
the DCS Encore Multimax ({\tt m.cs.uiuc.edu}, which has a total of
10 processors.  It should also noted that the {\bf kmultiqueuebest}
strategy was used for these performance tests; some other
message queueing strategy available with the Chare Kernel might give different
performance ratings. Evidently the queueing strategy we used was
experimental; it did not start up at all with certain numbers of
processors, and crashed with others, while the {\tt qs\_stack} strategy
worked correctly in all cases (although it resulted in greatly decreased
performance due to the LIFO message ordering).
The following table presents the performance
tests on the Multimax:

\begin{tabular}{||c|l||} \hline
  \# Procs.  &   Wall Time (secs)  \\ \hline
1  &	8.5 \\
2  &	Threads Disaster \\
3  &	Threads Disaster \\
4  &	4.5 \\
5  &	3.9 \\
6  &	ranged from 3.9 to 14.5 \\
7  &	Message: ``No PE-Queues Graph for 7 Processors'' \\
8  &	19.7 \\
9  &    Message: "No PE-Queues Graph for 9 Processors'' \\
10 &	6.6 \\ \hline
\end{tabular}

Notice that in this example, there were really only 4 chares (event and
state for Producer and Consumer) doing useful work, so adding processors
beyond 4 did not result in significant speedup.  We are unable to
explain the wide variations in some of the cases (e.g. 19.7 seconds on 8
processors, but six times as fast on just 5 processors), but two things
to suspect might be the dynamic load balancing algorithm used by the
Chare Kernel, and unpredictable loading conditions on the host machine.
(Machine {\tt m} is heavily used by many Computer Science personnel, and
we were unable to get exclusive use of CPU time for performance analysis.)

%%======================================================================
\section {Synchronization Simulation Test Case}
This is a second test case for testing and demonstrating some
additional features of \dispare, such as the ability to properly 
synchronize between various sets of events.  
The following diagram will
provide some insight on the structure of the test case.
 
\begin{figure}
\label{drawing2}
\centerline{\psfig{figure=simtestb.ps}}
\caption { Synchronization Simulation Test Case}
\end{figure}

The above model maps out some of the events that will be placed in
the simualtion.  The objective of this test is to demonstrate
\dispare's ability to handle multiple synchronized events.  In
the above model Phase-A,B,C,D will generate an object
simultaneously and send these objects to Intermediate-1,2 events.  
The Intermediate events in turn will eventually send the 
captured objects to the FEND event. The next section will provide more
detail on the interworkings of the various events.
 
\subsection{Phase-A,B,C,D}
All of these events are of the same type and nature. 
All events are
programmed to produce a new object every TIME+100 time steps.  The
object produced will correspond to the sequence in which the objects
were  produced by the Phase Events.  Phase events A, B will send
their output simultaneously to the Intermediate-1 event, while Phase
events C, D will send their objects to Intermediate-2 event. All
Phase events will also record the creation time of the current object
and write the time of the next object to be created. All Phase events will
then send their objects to the appropriate intermediate events and
then call themselves  with a new time step of for creating a new
object.  
 
This part of the simulation test will evaluate the fact
that all starting events all will be occuring  simultaneous in simulation
time. This test will identify if there are any time-steps problems
for multiple starting events.  This phase of the test will also examine the
self-looping feature, making sure \dispare is properly updating
the time-steps, as the simulator moves the events in time.  The
objects that are sent have IDs, and Creation times tags as they are
sent to the Intermediate events.
 
\subsection{Intermediate-1,2}
This set of events are the receivers of objects 
from the Phase events.  Each of these
events will receive pairs of objects.  Intermediate-1 will receive
objects from Phase-A and B simultaneously, while Intermediate-2
will receive objects simultaneously from Phase-C,D.  All
objects will have an identification number and creation time tag.  
Each Intermediate event will take both of these objects and place them
in a Queue of a finite size. A new field that will be associated
with the object's entry time into the queue.  The entry time for
both objects from A,B or C,D will be equal.
Once the queue is full. The queued objects will be emptied from
the queue in FIFO manner into the FEND event. Both Intermediate
events will be sending data simultanously to FEND event.  Each item
released from the queue will occur in increments of exactly one 
time step apart for each item released from the queue.
 
The objectve of these events is to test the synchronization of
incoming event messages/data. Both Intermediate events will be 
receiving the identical object identification numbers
from Phase-A,B,C,D at the same time. 
Timing information will be stored with the Object data. The second
objective of this event is to test the event state management of variables.
The Intermediate internal queues are used to identify if information about the
event state is being missed managed.  When the data is send to
FEND where it will be printed out, we should find that first 4 objects
should have the same id number, creation time, and entry time.
Secondly the id number should be in increasing order.  An example
of what the output is provided below:

\begin {tabular}{||c|c|c||} \hline
Object ID &   Creation Time &        Entry Time \\ \hline
1   &             10  &                 11 \\
1  &              10  &                11 \\
1  &              10       &          11  \\
1 &               10  &                 11 \\
2 &               100  &               101  \\
2 &               100  &                 101 \\
2 &               100  &                 101 \\
2 &                100  &                 101 \\ \hline
\end {tabular}
 
\subsection{FEND}
This event is used just to bring all the information together to be
printed out in one file.  This event requires that Intermediate-1,2
be synchronized when they are flushing there queues.  This event will
also print out the time at which the object is being printed.
 
\subsection{Results}
This section presents some of the results from the second simulation
test.  Again it is important to validate that the simulation models are
working properly.  The simlulation was set up in such a way that
the Phase events will record objects'  time of
generation and time at which the next object is scheduled to be
generated.  This information is important for validation of the self
loops of the Phase events.  This information can also be coordinated
with the other reports to determine whether the objects are arriving at
the receiving events in correct order.  The {\tt final.rep} file will
contain infomation that indicates the object's identification number,
arrival time at the intermediate events, and arrival time at the
FEND event. All the reports were consistent, meaning that the simulation
is unfolding properly in simulation time. The report files for this test
case are attached.
 
\subsection {Performance Evaluation}

The following chart outlines the performance of the second test case.
All the comments regarding the performance of the first test case apply
here as well.

\begin{tabular}{||c|l||} \hline
  \# Procs.  &   Wall Time (secs) \\ \hline
	1   &	43.0  \\
	2   &	Threads Disaster  \\
	3   &	Threads Disaster  \\
	4   &	47.3  \\
	5   &	40.2  \\
	6   &	45.7  \\
	7   &	Message: ``No PE-Queues Graph for 7 Processors''  \\
	8   &	32.9  \\
	9   &	Message: ``No PE-Queues Graph for 9 Processors'' \\
	10  &	80.7 \\ \hline
\end{tabular}

\subsection{Performance Notes}

Clearly the table above does not demonstrate significant performance
increases as processors are added (although, as was mentioned
previously, there was often wide variation in the execution times for a
given configuration).  The following thoughts may help explain this.

The state and event chares for a given event type are spawned
arbitrarily (i.e. without respect to which PE they will be on) in the
current implementation.  Since these two chares communicate heavily, and
the length of the messages between them is user-defined, perhaps a
performance advantage might be realized if we forced them to be created
on the same PE when there are fewer PE's than chares.  The rationale is
that if there are fewer PE's, then some chares will be forced to share a
PE, in which case we might as well force the state and event chares for
a given event type to be on the same PE since they communicate so
heavily.  The number of PE's can be determined at runtime and so this
modification to the code would not be difficult.  Of course, if a
particular event instance does a lot of CPU work before returning
control to the state chare, it might still be worthwhile to keep them on
different PE's, so that the state chare could receive and buffer
scheduling requests while the event chare was executing.

Also, in this second test case, there are 14 chares (corresponding to
the 7 event types) as compared to just 4 for the first test case, so
differences in performance due to the load balancing or allocation
strategy should be much more noticeable here.  This helps explain why
the speedup was more pronounced in the first test case; perhaps with
different allocation this test case would have had similar performance.

We intend to look into this issue further in the near future, and we hope
to test \dispare on various different machines using different message
queueing and load balancing strategies. 
 
\section{General Guidelines for \dispare}
This section presents some general guidelines that a user should
follow in writting \dispare simulation code.  
To maximimize potential parallelism,
the user should avoid using loops within an event instance to advance
time and simulate multiple instances of the event.
The way to advance time is to
perform a self-loop event call, and let \dispare and the Chare Kernel
dynamically schedule it.  The user can
examine the current state variables to determine whether a loop has
completed.  

Also, because there is no concurrency within a chare in the Chare
Kernel, the user should not write a loop that ``busy waits'' until a
certain simulation timestep, as it will wait forever.  Instead, the
event instance should check  the value of TIME, and if the desired time
has not elapsed, do nothing and fall through to the end of the event code.
 
The second guideline is that simulation designers should not use any
type of dynamic storage, because there is no way for \dispare to
figure out what the dynamic storage looks like from time step to
time step. Simulation designers should use array storage or some
other static storage technique. For example, in the test case an
array structure was used to implement the Queuing system for the 
{\em Consumers}.\footnote{In practice, as explained in Chapter
\ref{input}, dynamic storage allocation should be possible within an
event instance, but not within the state structures.}
 
A third guideline is that all variables that will be used to 
identify the state of the event should be kept in the STATE
structure for that event.  The event instance local variables behave
just as function local variables do: they are reinitialized at every
event instance.
 
Events should be designed such that once an
event message is received by an event,  the event should do as
much work as possible before the event is terminated.
To illustrate this idea, Consumer1 and Consumer2 both have
large busy loops which can be done is parallel since neither event
 depends on the other. Also at the same time the 
{\bf Producer} can still be producing objects, hence everyone is doing 
work which speeds up the simulation.

More generally, the user should try to insure that the message sending
overhead is small compared to the amount of useful work done by an
event.  If the input and state structures are very elaborate, message
overhead increases.  In particular, although it is legal to declare
fixed-size arrays in these structures, the whole array gets passed as
part of the message.  

\subsection{Summary}

\dispare can be used to run various types of simulations
that use synchronous timing mechanisms between events.  Simulations that
can take advantage of \dispare include General Stochastic Petri Nets
(GSPN), which are simulations that require setting up various types of
events (places) with links declared between events (transitions). GSPN's
have been used extensively in Reliability/Performance Modelling.
Normally GSPN's are represented as reachability graphs and then 
converted into  Markov chains.  There are many cases where the GPSN
cannot be computed because the Markov chain model is too large to be
solved.  This is where \dispare can be of help:  the user can express
the GSPN in C, and 
\dispare can simulate what happens. Hence the user can specify
large GSPN models and the models can be solved by using the simulation
results. The other advantage of \dispare is the fact that it runs the
simulation in less time thann a sequential simulator; typical speedup
for \dispare is the minimum of the number of processors or the number of
event types. Because of this
speedup, larger simulation problems can be solved in the same time as a
sequential simulation running a small simulation problem.
